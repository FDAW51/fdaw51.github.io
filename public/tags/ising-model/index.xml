<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ising Model on Eugene</title>
        <link>http://localhost:1313/tags/ising-model/</link>
        <description>Recent content in Ising Model on Eugene</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Tue, 25 Nov 2025 17:40:16 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/ising-model/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Ising model 到 Predictive Coding-能量最小化的自然演进</title>
        <link>http://localhost:1313/2025/homeworkising-model-%E5%88%B0-predictive-coding-%E8%83%BD%E9%87%8F%E6%9C%80%E5%B0%8F%E5%8C%96%E7%9A%84%E8%87%AA%E7%84%B6%E6%BC%94%E8%BF%9B/</link>
        <pubDate>Tue, 25 Nov 2025 17:40:16 +0800</pubDate>
        
        <guid>http://localhost:1313/2025/homeworkising-model-%E5%88%B0-predictive-coding-%E8%83%BD%E9%87%8F%E6%9C%80%E5%B0%8F%E5%8C%96%E7%9A%84%E8%87%AA%E7%84%B6%E6%BC%94%E8%BF%9B/</guid>
        <description>&lt;h2 id=&#34;摘要&#34;&gt;摘要：
&lt;/h2&gt;
&lt;p&gt;本文系统探讨了统计物理模型与神经计算理论之间的深刻联系，阐述了基于“能量最小化”原理的计算框架如何从物理系统延伸至生物智能。&lt;/p&gt;
&lt;p&gt;文章首先回顾了Ising模型及其哈密顿量形式，并以此为基础介绍了**模拟退火（Simulated Annealing）与量子退火（Quantum Annealing）**算法。通过类比物理系统寻找最低能态的过程，解释了如何利用热涨落和量子隧穿效应克服局部极小值，从而解决复杂的组合优化问题（如NP问题）。&lt;/p&gt;
&lt;p&gt;随后，文章将物理自旋映射为神经元，引入了Hopfield神经网络。基于Hebbian学习规则，文章展示了神经网络的记忆存储与提取本质上是在塑造能量地貌（Energy Landscape），即通过突触权重的调整使得记忆状态对应于系统的能量基态。&lt;/p&gt;
&lt;p&gt;最后，针对传统Hebbian学习缺乏全局误差传导机制（信用分配问题）的局限，文章重点介绍了**预测编码（Predictive Coding, PC）理论。作为神经科学的前沿理论，PC通过构建分层高斯生成模型，引入了“状态单元”与“误差单元”的双重结构。文章详细推导了PC的自由能函数及动力学方程，揭示了大脑如何通过快速的神经元状态更新（感知推断）与慢速的突触权重更新（学习）**来最小化预测误差。结论指出，Predictive Coding在保持局部计算（生物学合理性）的同时，实现了类似反向传播的深度误差修正能力，为理解大脑的高级认知功能提供了强有力的数学解释。&lt;/p&gt;
&lt;p&gt;关键词： Ising模型，模拟退火，量子退火，Hopfield网络，Hebbian学习，预测编码 (Predictive Coding)，自由能原理，能量地貌&lt;/p&gt;
&lt;h2 id=&#34;1ising-model&#34;&gt;1.Ising Model
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.bdhammel.com/assets/ising_model/monte-carlo-ising-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;The Ising model&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基本概念&lt;/strong&gt;：统计物理中用于描述铁磁性的数学模型。系统由许多离散变量（自旋）组成，每个自选变量的取值为 $+1$ 或 $-1$。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哈密顿量 (能量函数)：&lt;/p&gt;
$$
   \begin{aligned}
   H(\sigma) = -\sum_{\langle i,j\rangle} J_{ij} \sigma_i \sigma_j - \mu \sum_{j} h_j \sigma_j
   \end{aligned}
   $$&lt;ul&gt;
&lt;li&gt;其中 $J_{ij}$ 代表每个自旋之间的相互作用强度，$h_j$ 代表外部磁场。第一项是相互作用能，第二项是外部磁场的能量。&lt;/li&gt;
&lt;li&gt;通过这个哈密顿量，就可以研究这个系统的相变过程以及其相变温度Tc。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-模拟退火算法simulated-annealing&#34;&gt;2. 模拟退火算法（Simulated annealing）
&lt;/h2&gt;
&lt;h3 id=&#34;解决的问题&#34;&gt;解决的问题：
&lt;/h3&gt;
&lt;p&gt;优化问题经常出现在我们的生活当中，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何在最短的时间内到达学校？&lt;/li&gt;
&lt;li&gt;如何以最低的价格买到想要购买的东西？&lt;/li&gt;
&lt;li&gt;如何选择合适的路线使得行驶的距离最短？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些问题在我们生活中其实不知不觉地在被解决，比如导航的app，购物的app，都无时无刻地在计算对于一类优化问题的最优解。&lt;/p&gt;
&lt;p&gt;那么它们是如何来解决优化问题的呢？&lt;/p&gt;
&lt;h3 id=&#34;物理上的启发&#34;&gt;物理上的启发：
&lt;/h3&gt;
&lt;p&gt;首先，一个优化问题可以转化成，假如你在一群山之间，这些山的高度不一样，你如何找到这群山中最低的地方。从物理的角度上说，就是如何找到一个能量（势能）最低点。&lt;/p&gt;
&lt;p&gt;模拟退火算法就是物理学家类比固体退火过程得出的。&lt;/p&gt;
&lt;p&gt;固体在温度比较高的时候，此时固体内部的原子剧烈运动（热运动剧烈的程度与温度相关），逐渐降温（退火过程）整个系统接近平衡，最终就会达到一个平衡态，这个平衡态的能量最低。&lt;/p&gt;
&lt;p&gt;其中，固体在温度T时处于能量E的状态的概率遵循Boltzmann分布：
&lt;/p&gt;
$$
P(E) \propto e^{-E/(kT)}
$$&lt;p&gt;
那么物理学家就将这么一个过程类比到一个优化问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将一个物理系统的能量类比为优化问题的目标函数 $f(x)$。&lt;/li&gt;
&lt;li&gt;温度T类比为在寻找最优解过程中“容忍坏解”的程度。&lt;/li&gt;
&lt;li&gt;物理系统的状态类比为优化问题的一个候选解。&lt;/li&gt;
&lt;li&gt;物理系统遵循Boltzmann分布的特性类比为优化问题中不同解之间的转变规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;具体算法&#34;&gt;具体算法：
&lt;/h3&gt;
&lt;p&gt;对于一个优化问题 $\min_{x} f(x)$，$f(x)$ 是目标函数。&lt;/p&gt;
&lt;p&gt;模拟退火算法的流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;随机初始化一个解&lt;/strong&gt; $f(x_0)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在当前解附近 &lt;strong&gt;生成一个新解 f(x)&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据能量变化 ΔE =f(x)-f(x0) 来决定是否接受新解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;若更好（ΔE &amp;lt; 0）：必然接受&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若更差（ΔE &amp;gt; 0）：以概率
&lt;/p&gt;
$$
     P = \exp(-\Delta E / T)
     $$&lt;p&gt;
接受&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;逐渐降低温度 T&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当温度很低时系统趋于稳定，返回最终解&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么其中有一个问题？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在算法的第二步中，如何选择/生成这样一个新解？（解决方案：随机生成但是随着温度的下降随机性变小。）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;3-量子退火算法&#34;&gt;3 .量子退火算法
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://henrywang7.com/wp-content/uploads/2014/01/quantum_annealing1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;首先，在经典中，想要找到全局的最优解需要翻过一些山峰。&lt;/p&gt;
&lt;p&gt;但是在量子中有一个著名的效应是量子隧穿效应，也就是说，当这个小球面对一个山峰时，它有概率直接穿过到达这座山的另一侧。&lt;/p&gt;
&lt;p&gt;那么这样一种神奇的效应正好可以克服经典模拟退火算法容易陷入局部最优解的问题，它使得候选解可以更快地离开局部最优。&lt;/p&gt;
&lt;h3 id=&#34;ising-model的引入&#34;&gt;Ising model的引入
&lt;/h3&gt;
&lt;p&gt;在组合优化问题中有这样一条定理：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;任意NP类型组合优化问题（SAT、Max-Cut、TSP、Partition、QUBO…）
其目标函数都可以转成 &lt;strong&gt;二值变量的二次型&lt;/strong&gt;：
&lt;/p&gt;
$$
   E(x) = x^T Q x
   $$&lt;p&gt;
其中 $x_i \in \{0,1\}$ 或 $x_i=\pm1$。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;而Ising model的哈密顿量：
&lt;/p&gt;
$$
H = -\sum_{i&lt;j} J_{ij} \sigma_i^z \sigma_j^z - \sum_i h_i \sigma_i^z
$$&lt;p&gt;
可以发现，Ising model中的能量函数与组合优化问题中二值变量的二次型类似，其中自旋的取值为正负1。因此可以通过Ising model 的哈密顿量来表达所有NP类型的组合问题的哈密顿量。&lt;/p&gt;
&lt;h3 id=&#34;具体流程&#34;&gt;具体流程
&lt;/h3&gt;
&lt;p&gt;首先我们将目标函数类比为经典Ising model的哈密顿量：&lt;strong&gt;经典 Ising 哈密顿量（目标函数）：&lt;/strong&gt;
&lt;/p&gt;
$$
H_C = -\sum_{i&lt;j} J_{ij} \sigma_i^z \sigma_j^z - \sum_i h_i \sigma_i^z
$$&lt;p&gt;
其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\sigma_i^z$ 是 Pauli Z 矩阵&lt;/li&gt;
&lt;li&gt;自旋向上对应 $s_i = +1$，向下对应 $s_i = -1$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后我们加入一个量子涨落（一个外部的扰动/影响），使得整个系统可以进行量子隧穿：
&lt;/p&gt;
$$
H_D = -\Gamma \sum_i \sigma_i^x
$$&lt;p&gt;
其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\sigma_i^x$ 会翻转自旋（量子涨落）&lt;/li&gt;
&lt;li&gt;$\Gamma$ 是横场强度（影响整个系统x方向上的自旋）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将两个项结合就是总的哈密顿量：
&lt;/p&gt;
$$
H(t) = A(t) H_D + B(t) H_C
$$&lt;p&gt;
边界条件：
&lt;/p&gt;
$$
\begin{aligned}
A(0) &amp;= 1,\quad B(0) = 0 &amp;&amp; \text{（完全量子）} \\
A(T) &amp;= 0,\quad B(T) = 1 &amp;&amp; \text{（完全经典）}
\end{aligned}
$$&lt;p&gt;
从初始哈密顿量：
&lt;/p&gt;
$$
H(0) = H_D
$$&lt;p&gt;
一开始系统的状态为：
&lt;/p&gt;
$$
|\psi(0)\rangle = \bigotimes_i \frac{|0\rangle_i + |1\rangle_i}{\sqrt{2}}
$$&lt;p&gt;
也就是 &lt;strong&gt;所有自旋均匀叠加&lt;/strong&gt;，完全无偏（这么选择的原因是：这个状态是 $\sigma_x$的本征态，并且这个态可以通过演化到达其他所有的状态，因此就允许了系统在一开始能够对于整个状态空间的量子态进行搜索）。&lt;/p&gt;
&lt;p&gt;最终哈密顿量：
&lt;/p&gt;
$$
H(T) = H_C
$$&lt;p&gt;
最终哈密顿量的基态即为优化问题的最优解（因为基态的能量最低，前面将优化问题的目标函数类比为Ising model的能量，那么最优解对应的态自然就是基态）。&lt;/p&gt;
&lt;p&gt;那么现在有1个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何保证系统能够演化到最终的最优解的状态？&amp;mdash;-（量子绝热定理）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hopfield-神经网络&#34;&gt;Hopfield 神经网络
&lt;/h2&gt;
&lt;p&gt;Ising model 是固定不同自旋之间的耦合强度 $J_{ij}$，通过改变温度，来观察这些自旋之间的集体行为（相变，相变温度 $T_c$）。那么基于Ising model 的Quantum Annealing 其实也是同理的。&lt;/p&gt;
&lt;p&gt;人大脑中的神经元与自旋类似。当人接收到外部信息时，这些神经元要么处于激活状态（+1），要么处于未激活状态（-1），并且神经元之间由突触连接，这个连接的强度变化由早期的Hebbian Theory决定：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当对于某一个事件而言，若两个神经元之间同时处于激活状态，那么它们之间的连接强度增强。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;由此，Hopfield就联想到了物理中的Ising Model：
&lt;/p&gt;
$$
 E=-\frac{1}{2}\sum_{i,j}J_{ij}\sigma_i\sigma_j
$$&lt;p&gt;
这里不考虑外部影响，只考虑神经元之间的耦合，每个神经元都与其他所有的神经元有连接（这个连接时对称的，即A和B之间的耦合强度 $J_{AB} = J_{BA}$）。&lt;/p&gt;
&lt;p&gt;仅仅用Ising model来解释神经元之间的连接是不够的，还需要解释，一个神经网络是如何学习与回忆的。&lt;/p&gt;
&lt;h3 id=&#34;记忆&#34;&gt;记忆：
&lt;/h3&gt;
&lt;p&gt;在解释神经网络是如何学习与回忆之前，有一个重要的概念就是记忆。在Ising model 中基态是能量最低的态，量子退火算法也是通过找到基态，从而找到了最优解，那么神经网络中也有一个基态，这个基态对应着记忆。&lt;/p&gt;
&lt;p&gt;为什么记忆就是基态呢？&lt;/p&gt;
&lt;p&gt;可以这样理解，当你在处理某一类的问题时，就像将小球丢进一个记忆空间中（这个记忆空间其实是你学习过程中形成的），当你在回忆你的记忆时，其实就是小球滚动寻找下图中最低点的过程（寻找基态的过程）&lt;/p&gt;
&lt;img src=&#34;https://media.licdn.com/dms/image/v2/C4D12AQEDnTuwZCVx1Q/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1538577454555?e=2147483647&amp;v=beta&amp;t=d6SKEEOQzdF6aqyLwFCSzY3lahC6aCkg1x9grYMwEJI&#34; alt=&#34;Understanding Deep Learning through Energy Landscapes&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;h3 id=&#34;学习&#34;&gt;学习：
&lt;/h3&gt;
&lt;p&gt;假设有N个神经元，正在学习某一个方面的内容，接收信息，更新N个神经元之间的连接强度 $W_{ij}$:
&lt;/p&gt;
$$
W_{ij}=\frac{1}{N}\sum_{\mu=1}^P\xi_i^\mu\xi_j^\mu
$$&lt;p&gt;
其中i,j 表示不同的神经元。&lt;/p&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;P表示接受的信息有P个patterns ，比如说你在学习如何识别图片中的内容，你接收到了三张图片（“A”，“B”，“笑脸”），此时就有3个Patterns的信息&lt;/li&gt;
&lt;li&gt;$\xi_j^\mu$表示第j个神经元对于第 $\mu$个pattern的反应，比如对于图片A，3号神经元是Active的，但是4号神经元却是睡觉。&lt;/li&gt;
&lt;li&gt;重复学习会导致什么结果？&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;回忆&#34;&gt;回忆：
&lt;/h3&gt;
&lt;p&gt;当你完成了对于某一个方面内容的学习，下一次你需要这方面内容的时候，你就需要去回忆&amp;ndash;找到这个记忆&amp;ndash;找到当前记忆空间中的最低谷。&lt;/p&gt;
&lt;p&gt;此时，神经元之间的强度固定（其实应该是减弱的，但是是整体减弱，所以忽略），但是此时你神经元的状态却是随机的，所以回忆的过程是：在记忆空间中，随机地释放小球，让小球寻找记忆的过程。&lt;/p&gt;
&lt;p&gt;举一个具体的例子就是，比如说图片识别，当一个神经网络学会了图像识别，当放一个模糊的照片给神经网络，让其进行识别，那么此时网络就会按照如下的规则来更新每个神经元的状态：
&lt;/p&gt;
$$
S_i\leftarrow\mathrm{sign}\left(\sum_jW_{ij}S_j\right)
$$&lt;p&gt;
这个规则要表达的意思其实是将第i个神经元周围所有神经元的状态及其突触连接强度综合起来，去更新其状态。sign函数是一个符号函数，内部结果大于0，则返回1，反之-1。&lt;/p&gt;
&lt;h3 id=&#34;问题&#34;&gt;问题：
&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;重复学习在神经网络中的效果是什么？&lt;/li&gt;
&lt;li&gt;如果神经元之间的连接强度不对称会发生什么&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;展望与思考&#34;&gt;展望与思考
&lt;/h2&gt;
&lt;p&gt;量子退火算法使用Ising model，通过加入量子涨落，并缓慢地降温，使得系统一开始可以探索所有可能性的空间，最后让基态落在最优解上。&lt;/p&gt;
&lt;p&gt;Hopfield 神经网络 通过Ising model 与神经元网络之间的类比，并结合神经科学中的Hebbian learning theory ，使得神经网络有了学习，回忆等功能。&lt;/p&gt;
&lt;p&gt;那么问题是：随着神经科学的不断进步，人类对于大脑的研究更加深入，Hebbian learning theory 可不可以替换成现在对于神经元研究最新的理论，使得这个神经网络更加强大呢？&lt;/p&gt;
&lt;p&gt;答案是：Predictive Coding&lt;/p&gt;
&lt;h3 id=&#34;predictive-coding&#34;&gt;Predictive Coding
&lt;/h3&gt;
&lt;p&gt;传统的认知观点认为大脑像一个“照相机”：接收外界信号 -&amp;gt; 处理信号 -&amp;gt; 产生感知。 &lt;strong&gt;Predictive Coding（PC）&lt;/strong&gt; 则认为大脑有两层-高层区域和底层区域，其中高层区域负责预测，底层区域负责接收真实的输入，比如当我们看到一个只有两个腿的动物，高层就会认为我们看到的是一个人，而底层告诉高层，看到的是一个袋鼠，那么这时候就产生了误差。：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;自顶向下（Top-Down）的预测：&lt;/strong&gt; 大脑的高层区域（概念层）时刻在根据记忆和经验，向低层区域（感觉层）发送“预测”信号（它认为现在的世界是什么样的）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自底向上（Bottom-Up）的误差：&lt;/strong&gt; 感觉器官接收真实的输入。如果输入和预测不一致，就会产生**“预测误差”（Prediction Error）**。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;误差传递与更新：&lt;/strong&gt; 只有这个“误差”信号会向上传递，用来修正高层的模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此PC认为大脑的核心目标是最小化高层区域的预测误差。其数学过程如下：&lt;/p&gt;
&lt;p&gt;我们将 Predictive Coding 看作一个&lt;strong&gt;分层高斯生成模型（Hierarchical Gaussian Generative Model）&lt;/strong&gt;。为了简化，我们只看两层：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;观测层 (Level 0):&lt;/strong&gt; $\mathbf{x}$ (感觉输入)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐层 (Level 1):&lt;/strong&gt; $\mathbf{r}$ (大脑内部的表征/状态)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;1-定义能量函数-the-energy-function&#34;&gt;1. 定义能量函数 (The Energy Function)
&lt;/h4&gt;
&lt;p&gt;在物理学中，系统倾向于演化到能量最低的状态。在这里，我们定义一个目标函数 $F$（即变分自由能的简化形式，在统计学上等价于负对数似然），它衡量了“预测误差”的大小。&lt;/p&gt;
&lt;p&gt;假设高层 $\mathbf{r}$ 通过权重矩阵 $W$ 线性预测低层，预测值为 $\hat{\mathbf{x}} = W\mathbf{r}$。&lt;/p&gt;
&lt;p&gt;此时，预测误差 $\mathbf{e}$ 为：&lt;/p&gt;
$$\mathbf{e} = \mathbf{x} - W\mathbf{r}$$&lt;p&gt;为了同时满足“解释数据”和“先验约束（Prior）”，总能量 $F$ 通常被定义为：&lt;/p&gt;
$$
\begin{aligned}
F &amp;= \underbrace{\frac{1}{2} \lVert \mathbf{x} - W\mathbf{r} \rVert^2}_{\text{Sensory Prediction Error}} \\
  &amp;\quad + \underbrace{\frac{\lambda}{2} \lVert \mathbf{r} - \mathbf{r}_{\text{prior}} \rVert^2}_{\text{Prior Prediction Error (Regularization)}}
\end{aligned}
$$&lt;p&gt;
为简化讨论，我们暂时忽略先验项，只关注第一项（感觉误差）。&lt;/p&gt;
&lt;h4 id=&#34;2-两个过程推断-inference-与-学习-learning&#34;&gt;2. 两个过程：推断 (Inference) 与 学习 (Learning)
&lt;/h4&gt;
&lt;p&gt;Predictive Coding 的核心在于它将神经网络的运作分为了两个不同时间尺度的动力学过程：&lt;strong&gt;快过程（神经元活动）**和**慢过程（突触可塑性）&lt;/strong&gt;。两者都是为了最小化 $F$。&lt;/p&gt;
&lt;h5 id=&#34;a-快过程神经元状态更新-inference&#34;&gt;A. 快过程：神经元状态更新 (Inference)
&lt;/h5&gt;
&lt;p&gt;当一张图片 $\mathbf{x}$ 输入进来时，权重 $W$ 是固定的。网络需要调整神经元状态 $\mathbf{r}$，使其生成的预测尽可能接近 $\mathbf{x}$。这就是“感知”。&lt;/p&gt;
&lt;p&gt;我们在 $\mathbf{r}$ 空间进行梯度下降：&lt;/p&gt;
$$\dot{\mathbf{r}} = -\frac{\partial F}{\partial \mathbf{r}}$$&lt;p&gt;计算梯度：&lt;/p&gt;
$$\frac{\partial F}{\partial \mathbf{r}} = \frac{\partial}{\partial \mathbf{r}} \left( \frac{1}{2} (\mathbf{x} - W\mathbf{r})^T (\mathbf{x} - W\mathbf{r}) \right) = -(\mathbf{x} - W\mathbf{r})^T W = -\mathbf{e}^T W$$&lt;p&gt;所以，神经元的动力学方程为：&lt;/p&gt;
$$\dot{\mathbf{r}} = W^T \mathbf{e}$$&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;物理直觉：&lt;/strong&gt; 这是一个&lt;strong&gt;局部计算&lt;/strong&gt;。误差 $\mathbf{e}$ 在底层计算出来，通过转置矩阵 $W^T$（反馈连接）传回高层，驱动 $\mathbf{r}$ 改变，直到预测误差最小化（即 $\dot{\mathbf{r}} \to 0$）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;b-慢过程突触权重更新-learning&#34;&gt;B. 慢过程：突触权重更新 (Learning)
&lt;/h5&gt;
&lt;p&gt;这是你最关心的部分。当我们推断出较好的 $\mathbf{r}$ 后（或者在推断的同时），我们需要更新突触权重 $W$，以便下次能更准地预测。&lt;/p&gt;
&lt;p&gt;我们在参数 $W$ 空间进行梯度下降：&lt;/p&gt;
$$\dot{W} = -\mu \frac{\partial F}{\partial W}$$&lt;p&gt;其中 $\mu$ 是学习率。计算梯度：&lt;/p&gt;
$$\frac{\partial F}{\partial W} = -(\mathbf{x} - W\mathbf{r}) \mathbf{r}^T = -\mathbf{e} \mathbf{r}^T$$&lt;p&gt;所以，权重的更新规则为：&lt;/p&gt;
$$\Delta W \propto \mathbf{e} \cdot \mathbf{r}^T$$&lt;p&gt;或者写成张量形式（针对单个权重 $w_{ij}$）：&lt;/p&gt;
$$\Delta w_{ij} \propto e_i \cdot r_j$$&lt;h4 id=&#34;pc与hopfield-神经网络的区别&#34;&gt;PC与Hopfield 神经网络的区别：
&lt;/h4&gt;
&lt;p&gt;Hopfield 神经网络中的神经元是局部的，它只关心他和邻居有没有同时处于激活状态，但是不知道整体网络的目标是什么？（例如：这张图是不是猫？），所以当这个网络变深之后，就不知道哪个神经元应该为错误的输出负责，去纠正错误。&lt;/p&gt;
&lt;p&gt;现代深度学习使用反向传播解决了这个谁应该为错误负责的问题。具体是这样：比如当我们在做图像识别的时候，当我识别出的图片与目标图片存在偏差的时候，这时候计算出一个损失函数，这个损失函数通过反向传播可以看到谁对这个偏差的影响更大，此时通过调整对应的神经元即可修正这个偏差。但是问题是，大脑中并没有这种误差传导通路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PC 的巧妙之处：&lt;/strong&gt; PC 引入了一种层级化的**“预测-纠错”机制**。你可以把它理解为每一层都有了自己的“质检员”（误差单元）。其中高层向下层发送预测，下层向上层反馈误差。 通过这种结构，PC 将原本遥不可及的“全局大目标”，转化为了每一层都能直接看到的“局部小目标”。神经元不再需要等待全局指令，只需要消除眼前的预测误差，就能自动引导整个网络走向最优解。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ernst Ising (1925).&lt;/strong&gt; &lt;em&gt;Beitrag zur Theorie des Ferromagnetismus&lt;/em&gt;. Zeitschrift für Physik.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kirkpatrick, S., Gelatt, C. D., &amp;amp; Vecchi, M. P. (1983).&lt;/strong&gt; &amp;ldquo;Optimization by Simulated Annealing&amp;rdquo;. &lt;em&gt;Science&lt;/em&gt;, 220(4598), 671-680.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kadowaki, T., &amp;amp; Nishimori, H. (1998).&lt;/strong&gt; &amp;ldquo;Quantum annealing in the transverse Ising model&amp;rdquo;. &lt;em&gt;Physical Review E&lt;/em&gt;, 58(5), 5355.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Farhi, E., et al. (2001).&lt;/strong&gt; &amp;ldquo;A Quantum Adiabatic Evolution Algorithm Applied to Random Instances of an NP-Complete Problem&amp;rdquo;. &lt;em&gt;Science&lt;/em&gt;, 292(5516), 472-475.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hebb, D. O. (1949).&lt;/strong&gt; &lt;em&gt;The Organization of Behavior: A Neuropsychological Theory&lt;/em&gt;. Wiley.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hopfield, J. J. (1982).&lt;/strong&gt; &amp;ldquo;Neural networks and physical systems with emergent collective computational abilities&amp;rdquo;. &lt;em&gt;Proceedings of the National Academy of Sciences (PNAS)&lt;/em&gt;, 79(8), 2554-2558.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Amit, D. J., Gutfreund, H., &amp;amp; Sompolinsky, H. (1985).&lt;/strong&gt; &amp;ldquo;Spin-glass models of neural networks&amp;rdquo;. &lt;em&gt;Physical Review A&lt;/em&gt;, 32(2), 1007.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Rao, R. P., &amp;amp; Ballard, D. H. (1999).&lt;/strong&gt; &amp;ldquo;Predictive coding in the visual cortex: a functional.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Friston, K. (2010).&lt;/strong&gt; &amp;ldquo;The free-energy principle: a unified brain theory?&amp;rdquo;. &lt;em&gt;Nature Reviews Neuroscience&lt;/em&gt;, 11(2), 127-138.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Whittington, J. C., &amp;amp; Bogacz, R. (2017).&lt;/strong&gt; &amp;ldquo;An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity&amp;rdquo;. &lt;em&gt;Neural Computation&lt;/em&gt;, 29(5), 1229-1262.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Millidge, B., Tschantz, A., &amp;amp; Buckley, C. L. (2021).&lt;/strong&gt; &amp;ldquo;Predictive Coding: A Theoretical and Experimental Review&amp;rdquo;. &lt;em&gt;arXiv preprint arXiv:2107.12979&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
